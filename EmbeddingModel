{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"EmbeddingModel","provenance":[{"file_id":"1YfOOZoX6v9O3eFpkBzDyvYbXOFKfzzJB","timestamp":1590864211052}],"collapsed_sections":["uPK04V-bbzZb"],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KsiBUBF-cZmj","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ye-iMWZ1tjid","colab_type":"code","colab":{}},"source":["pip install vaderSentiment"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-05T07:34:21.793777Z","start_time":"2018-12-05T07:34:20.545429Z"},"id":"p7Q3gwWhbzXP","colab_type":"code","colab":{}},"source":["# Load the raw dataset, along with all the packages we used in our project\n","import gc\n","import itertools\n","import re\n","import string\n","import time\n","import warnings\n","from collections import Counter, defaultdict\n","from random import choice\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem.porter import *\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","from sklearn.feature_extraction import stop_words\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import roc_curve, auc, accuracy_score, roc_auc_score, f1_score, confusion_matrix, precision_recall_curve\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","from sklearn.decomposition import PCA\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","\n","import lightgbm as lgb\n","from xgboost.sklearn import XGBClassifier\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","\n","# from helperfunctions.PrettyConfusionMatrix import print_cm\n","\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-05T07:34:22.470277Z","start_time":"2018-12-05T07:34:21.796328Z"},"id":"vjUm40QzbzXT","colab_type":"code","colab":{}},"source":["# Loading MBTI raw dataset\n","mbti = pd.read_csv('/content/drive/My Drive/FYP-Embedding/mbti_1.csv', error_bad_lines=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2sKb_tdkbzXW","colab_type":"code","colab":{}},"source":["mbti.head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xLSiGzPIbzXb","colab_type":"code","colab":{}},"source":["stat = mbti['type'].value_counts()\n","plt.figure(figsize=(12, 4))\n","plt.bar(stat.index, stat.values)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tL4unKtbzXe","colab_type":"code","colab":{}},"source":["# Personality type for each aspect\n","\n","# Extroversion vs. Introversion\n","mbti['EorI'] = mbti['type'].apply(lambda x: x[0])\n","\n","# Intuition vs. Sensing\n","mbti['NorS'] = mbti['type'].apply(lambda x: x[1])\n","\n","# Thinking vs. Feeling\n","mbti['TorF'] = mbti['type'].apply(lambda x: x[2])\n","\n","# Judging vs. Perceiving\n","mbti['JorP'] = mbti['type'].apply(lambda x: x[3])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qDp3UCyNbzXh","colab_type":"code","colab":{}},"source":["ax = sns.countplot(x='variable', hue='value',\n","                   data=pd.melt(mbti.iloc[:, 2:]), palette=\"Set2\")\n","ax.set_xticklabels([\"introverted vs.extroverted\", \"intuition vs. sensing\",\n","                    \"feeling vs.thinking \", \"judging vs. perceiving\",\n","                    ], rotation=10, fontsize=11)\n","ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gwicBdiJbzXk","colab_type":"code","colab":{}},"source":["mbti['avg_comment_length'] = mbti['posts'].apply(lambda x: len(x.split())/50)\n","mbti['comment_length_var'] = mbti['posts'].apply(lambda x: np.var(\n","    [len(sentence.split()) for sentence in x.split('|||')]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tDuhL5fbzXm","colab_type":"code","colab":{}},"source":["mbti.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9oGrgqobzXr","colab_type":"code","colab":{}},"source":["# finding personality types list\n","types = list(mbti.iloc[:, 0].unique())\n","types = [t.lower() for t in types]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UVsYGB6ZbzXt","colab_type":"code","colab":{}},"source":["def post_preprocess(df):\n","    i = 0\n","    post_list = []\n","    length = len(df)\n","    lemmatiser = WordNetLemmatizer()\n","    print('Processing... Be patient')\n","\n","    for row in df.iterrows():\n","        # Progress bar\n","        i += 1\n","        if (i % 500 == 0 or i == length):\n","            print(f\"Progress bar：{round(i/length*100)}%\")\n","        # clean the posts\n","        posts = row[1].posts\n","        posts = re.sub(r'\\|\\|\\|', ' ', posts)\n","        posts = re.sub(r'http[\\S]*', '', posts).lower()\n","        posts = re.sub(\"[^a-z\\s]\", ' ', posts)\n","        posts = ' '.join([lemmatiser.lemmatize(w) for w in posts.split(\n","            ' ') if w not in stopwords.words('english')])\n","\n","        # Removing personality types\n","        for t in types:\n","            posts = posts.replace(t, '')\n","        post_list.append(posts)\n","\n","    return np.array(post_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cUtkU_tPopJk","colab_type":"code","colab":{}},"source":["# Preprocess data\n","processed_post = pd.read_csv('/content/drive/My Drive/FYP-Embedding/mbti_preprocessed_1.csv')\n","\n","processed_post.drop('Unnamed: 0', axis=1, inplace=True)\n","processed_post.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3W-v-PqbzXz","colab_type":"code","colab":{}},"source":["# A type consists of 4 capitals and each capital corresponds to 2 possible characteristics.\n","# For later encoding and modeling issues, let's tranfer them into separate binary code.\n","type_map = {'I': 0, 'E': 1, 'N': 0, 'S': 1, 'F': 0, 'T': 1, 'J': 0, 'P': 1}\n","types = {'EorI': 'Extroversion vs. Introversion', 'NorS': 'Intuition vs. Sensing',\n","                 'TorF': 'Thinking vs. Feeling', 'JorP': 'Judging vs. Perceiving'}\n","# transfer column 3-6 into binary code.\n","\n","\n","def type_preprocess(df):\n","    for i in range(2, 6):\n","        df.iloc[:, i] = df.iloc[:, i].map(type_map)\n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O7HucKBIbzX3","colab_type":"code","colab":{}},"source":["mbti = type_preprocess(mbti)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w52KhhVdbzX5","colab_type":"code","colab":{}},"source":["mbti.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GULFw7zDbzX9","colab_type":"code","colab":{}},"source":["mbti.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-05T07:35:10.719138Z","start_time":"2018-12-05T07:34:38.077159Z"},"id":"S81CL_vFbzYA","colab_type":"code","colab":{}},"source":["\n","# TFIDF Vectorization\n","# Using TFIDF, created a bag of words representation of each user's posts.\n","\n","# Parameters used here are the  best for model performance\n","vectorizer_tfidf = TfidfVectorizer(\n","    min_df=0.05, max_df=0.85, analyzer='word', ngram_range=(1, 2))\n","vectorizer_tfidf.fit(processed_post['processed_posts'])\n","\n","word_tfidf = vectorizer_tfidf.transform(processed_post['processed_posts'])\n","\n","word_tfidf_df = pd.DataFrame(data=word_tfidf.toarray(\n","), columns=vectorizer_tfidf.get_feature_names())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-05T07:35:10.748461Z","start_time":"2018-12-05T07:35:10.721671Z"},"id":"Q-JWrwI3bzYC","colab_type":"code","colab":{}},"source":["word_tfidf_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"meSaV934bzYF","colab_type":"text"},"source":["### Manual Feature Extraction"]},{"cell_type":"markdown","metadata":{"id":"Ik2mUrWcbzYF","colab_type":"text"},"source":["Manually extracting feature such as sentiment score, exclamation mark count, links count, etc. "]},{"cell_type":"code","metadata":{"scrolled":false,"id":"5KRJR2wobzYG","colab_type":"code","colab":{}},"source":["# Sentiment Score of clean post\n","analyzer = SentimentIntensityAnalyzer()\n","scores = []\n","length_p = len(processed_post)\n","for i in range(length_p):\n","    score = analyzer.polarity_scores(\n","        processed_post['processed_posts'][i])['compound']\n","    scores.append(score)\n","    # Print Progress\n","    if (i % 500 == 0 or i == length_p-1):\n","        print(f\"Progress bar：{round(i/length_p*100)}%\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t6Nr_gPnbzYJ","colab_type":"code","colab":{}},"source":["mbti['Sentiment'] = scores"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-E3shJWwbzYM","colab_type":"code","colab":{}},"source":["# Additional Cleaning\n","# Here we get rid of NaN sentiment scores. We also scale negative numbers with MinMaxScalar, since it can't be handled by Naive Bayes.\n","\n","# NaNs were found:\n","mbti.fillna(value=0, inplace=True)\n","# Naive Bayes can't handle negatives? Scale with MinMax\n","min_max_scaler = MinMaxScaler()\n","min_max_scaler.fit(np.array(mbti['Sentiment']).reshape(-1, 1))\n","sentiment_scaled = min_max_scaler.transform(\n","    np.array(mbti['Sentiment']).reshape(-1, 1))\n","mbti['Sentiment'] = sentiment_scaled"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tsB8Rt8PbzYQ","colab_type":"code","colab":{}},"source":["# Ellipses count\n","# Create a list of ellpsies count per user. This is an indicator for long posts\n","ellipses_count = [len(re.findall(r'\\.\\.\\.\\|\\|\\|', posts))\n","                  for posts in mbti['posts']]\n","# Append to dataset\n","mbti['Ellipses'] = ellipses_count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qcYPEQNibzYU","colab_type":"code","colab":{}},"source":["# Exclamation count\n","# Create a list of exclamation count per user.\n","exclamation_count = [len(re.findall(r'!', posts)) for posts in mbti['posts']]\n","# Append to dataframe\n","mbti['Exclamation'] = exclamation_count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ca7hj7ZlbzYW","colab_type":"code","colab":{}},"source":["# Question count\n","# Create a list of question count per user.\n","question_count = [len(re.findall(r'\\?', posts)) for posts in mbti['posts']]\n","# Append to dataframe\n","mbti['Question'] = question_count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OiVw87rwbzYZ","colab_type":"code","colab":{}},"source":["# Link count\n","# For each user, remove ||| to make it easier to find links.\n","user_posts = [re.sub(r'\\|\\|\\|', ' ', posts) for posts in mbti['posts']]\n","# Create a list of link count per user.\n","link_count = [len(re.findall(r'http[\\S]* ', posts)) for posts in user_posts]\n","# Append to dataframe\n","mbti['Links'] = link_count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0VysOoxbzYc","colab_type":"code","colab":{}},"source":["# Picture count\n","# Create a list of question count per user.\n","question_count = [len(re.findall(r'(\\.png)|(\\.jpg)', posts))\n","                  for posts in mbti['posts']]\n","# Append to dataframe\n","mbti['Picture'] = question_count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ElVvzZZobzYe","colab_type":"code","colab":{}},"source":["# Emojies count\n","def find_emoji(text):\n","    # REMOVE LATER ON\n","    text = text.lower()\n","\n","    text = re.sub(r'\\|\\|\\|', ' ', text)\n","\n","    slack_style_emojies = re.findall(r':[\\w\\d]+(\\-[\\w\\d]+)?:', text)\n","    text_style_emojies = re.findall(r':[\\-|\\s]?[d|\\)|\\(|p]', text)\n","\n","    return slack_style_emojies + text_style_emojies"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nv3p_29CbzYg","colab_type":"code","colab":{}},"source":["mbti['Emojies'] = mbti['posts'].map(lambda x: len(find_emoji(x)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MbTGYa9bzYi","colab_type":"code","colab":{}},"source":["# Upper case count\n","def del_punct(text):\n","    regex = re.compile('[' + re.escape(string.punctuation) + '\\\\r\\\\t\\\\n]')\n","    return regex.sub(\"\", text)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2UR_kYXrbzYk","colab_type":"code","colab":{}},"source":["temp = mbti['posts'].apply(lambda x: del_punct(x))\n","mbti['Upper'] = temp.apply(lambda x: len(\n","    [x for x in x.split() if x.isupper()]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"yFPo_wpNbzYm","colab_type":"code","colab":{}},"source":["mbti.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pjEhI7d5bzYo","colab_type":"text"},"source":["## Modeling"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-05T07:35:11.329948Z","start_time":"2018-12-05T07:35:10.750825Z"},"id":"YoEZh87tbzYp","colab_type":"code","colab":{}},"source":["# for saving time, load the data we have done in terms of feature engineering.\n","mbti = pd.read_csv(\"/content/drive/My Drive/FYP-Embedding/mbti_FE.csv\")\n","target = mbti.iloc[:, 2:6]\n","\n","X_tf = pd.concat([mbti.iloc[:, 6:], word_tfidf_df], axis=1)\n","# X_ct = pd.concat([mbti.iloc[:,6:],word_ct_df],axis=1)\n","mbti.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-05T07:35:14.159066Z","start_time":"2018-12-05T07:35:14.145428Z"},"id":"eSE4tHznbzYs","colab_type":"code","colab":{}},"source":["def plot_confusion_matrix(cm,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","\n","    types = {'EorI': 'Extroversion vs. Introversion', 'NorS': 'Intuition vs. Sensing',\n","             'TorF': 'Thinking vs. Feeling', 'JorP': 'Judging vs. Perceiving'}\n","\n","    classes = {'EorI': ['Extrovert', 'Introvert'], 'NorS': ['Sensing', 'Intuition'],\n","               'TorF': ['Thinking', 'Feeling'], 'JorP': ['Perceiving', 'Judging']}\n","\n","    fig, axs = plt.subplots(2, 2, figsize=(\n","        10, 10), facecolor='w', edgecolor='b')\n","    axs = axs.flatten()\n","    k = 0\n","\n","    v_max = max(np.ndarray.flatten(np.array(list(cm.values()))))\n","\n","    for col in cm.keys():\n","        # interpolation changes the blurriness of the squares\n","        x = axs[k].imshow(cm[col], cmap=cmap, vmin=0.1, vmax=.5)\n","        axs[k].set_title(types[col], fontweight='bold')\n","        tick_marks = np.arange(len(classes[col]))\n","        axs[k].set_xticks(tick_marks)\n","        axs[k].set_xticklabels(labels=classes[col])\n","        axs[k].set_yticks(tick_marks)\n","        axs[k].set_yticklabels(labels=classes[col])\n","        axs[k].grid(which='minor', color='black')\n","        axs[k].axhline(0.5, color='black', linewidth=0.5)  # horizontal lines\n","        axs[k].axvline(0.5, color='black', linewidth=0.5)\n","        for i, j in itertools.product(range(cm[col].shape[0]), range(cm[col].shape[1])):\n","            axs[k].text(j, i, format(cm[col][i, j], '.1%'),\n","                        horizontalalignment=\"center\",\n","                        color=\"white\" if cm[col][i, j] > v_max/1.5 else \"black\")  # if color is darker, use white\n","        axs[k].set_ylabel('True label')\n","        axs[k].set_xlabel('Predicted label')\n","        plt.tight_layout()\n","        k += 1\n","\n","    fig.subplots_adjust(right=0.93)\n","    cbar_ax = fig.add_axes([0.95, .15, 0.01, .65])\n","    fig.colorbar(x, cax=cbar_ax)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-05T07:35:16.055261Z","start_time":"2018-12-05T07:35:16.044541Z"},"id":"peJv9nstbzYu","colab_type":"code","colab":{}},"source":["def get_plot_data(probabilities):\n","    '''\n","    Calculates average ROC and Precision vs Recall curves. \n","\n","    Function returns a dictionary with keys of class 'EorI', 'NorS', 'TorF', and 'JorP'.  \n","    \n","    '''\n","    model_data = defaultdict()\n","    base_x = np.linspace(0, 1, 101)\n","\n","    for types in probabilities.keys():\n","        model_data[types] = {'base_x': base_x, 'est_tpr': np.zeros(101), 'auc_roc': [], 'est_pr': np.zeros(101),\n","                             'auc_pr': []}\n","        total_splits = len(probabilities[types])\n","        for split in probabilities[types]:\n","            # split[0] is the model probability of predicting a 1\n","            y_scores = split[0]\n","            # split[1] is the true test values for that split\n","            y_true = split[1]\n","            fpr, tpr, thresholds = roc_curve(\n","                y_true, y_scores)  # used for interpolation\n","            precision, recall, thresholds = precision_recall_curve(\n","                y_true, y_scores)\n","            # Add est_tpr\n","            model_data[types]['est_tpr'] += np.interp(base_x, fpr, tpr)\n","            # Add est_precision\n","            model_data[types]['est_pr'] += np.interp(\n","                base_x, recall[::-1], precision[::-1])\n","            model_data[types]['auc_roc'].append(auc(fpr, tpr))  # Append AUC\n","            model_data[types]['auc_pr'].append(\n","                auc(recall, precision))  # Append AUC\n","        model_data[types]['est_tpr'] = model_data[types]['est_tpr'] / \\\n","            total_splits  # Average TPRs\n","        model_data[types]['est_pr'] = model_data[types]['est_pr'] / \\\n","            total_splits  # Average TPRs\n","        model_data[types]['auc_roc'] = np.mean(\n","            model_data[types]['auc_roc'])  # Average AUC-ROC\n","        model_data[types]['auc_pr'] = np.mean(\n","            model_data[types]['auc_pr'])  # Average PR\n","\n","    return model_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-05T07:35:16.654105Z","start_time":"2018-12-05T07:35:16.649934Z"},"id":"EcSqgVF_bzYx","colab_type":"code","colab":{}},"source":["def threshold_search(y_true, y_proba):\n","    '''\n","    searching a threshold to find the best f1-score\n","    '''\n","    best_threshold = 0\n","    best_score = 0\n","    for threshold in [i * 0.01 for i in range(100)]:\n","        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n","        if score > best_score:\n","            best_threshold = threshold\n","            best_score = score\n","#     search_result = {'threshold': best_threshold, 'f1': best_score} print if u want\n","    return best_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-05T07:35:17.057320Z","start_time":"2018-12-05T07:35:17.046800Z"},"id":"StzSc-WpbzY1","colab_type":"code","colab":{}},"source":["def model(model, X, target, nsplits=4):\n","    ''' Estimates probabilities for observations being in class 1.  '''\n","\n","    kf = StratifiedShuffleSplit(n_splits=nsplits, random_state=420)\n","    model_data = defaultdict()\n","    cms = defaultdict()\n","    df = pd.DataFrame(columns=['Average AUC', 'Average F_score'])\n","\n","    types = {'EorI': 'Extroversion vs. Introversion', 'NorS': 'Intuition vs. Sensing',\n","             'TorF': 'Thinking vs. Feeling', 'JorP': 'Judging vs. Perceiving'}\n","\n","    t = time.time()\n","    for col in target.columns:\n","        y = target[col]\n","        all_auc = []\n","        all_accuracies = []\n","        f_score = []\n","        model_data[col] = []\n","        avg_cm = np.zeros(4).reshape(2, 2).astype(int)\n","        for train, test in kf.split(X, y):\n","            X_train, X_test, y_train, y_test = X.loc[train], X.loc[test], y[train], y[test]\n","            model.fit(X_train, y_train)\n","            probabilities = model.predict_proba(X_test)\n","            score = probabilities[:, 1]\n","            preds = model.predict(X_test)\n","            model_data[col].append((score, y_test))\n","            all_auc.append(roc_auc_score(y_test, score))\n","            fscore = threshold_search(y_test, score)\n","            f_score.append(fscore)\n","            avg_cm += confusion_matrix(y_test, preds, [1, 0])\n","        avg_cm = avg_cm/nsplits\n","        avg_cm = avg_cm/np.sum(avg_cm)\n","        cms[col] = avg_cm\n","        df.loc[types[col]] = [np.mean(all_auc), np.mean(f_score)]\n","    print(df)\n","    plot_confusion_matrix(cms)\n","    print(f\"Time use:{time.time()-t:.3f}s\")\n","\n","    return get_plot_data(model_data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I0N08I4ObzY3","colab_type":"text"},"source":["## Naive Bayes"]},{"cell_type":"code","metadata":{"ExecuteTime":{"start_time":"2018-12-05T07:35:19.027Z"},"scrolled":false,"id":"GwP5AzjCbzY4","colab_type":"code","colab":{}},"source":["MNB = MultinomialNB()\n","mnb_tf_model = model(MNB, X_tf, target, nsplits=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0TwEq-L_bG4a","colab_type":"code","colab":{}},"source":["import pickle\n","filename = '/content/drive/My Drive/FYP-Embedding/finalized_model_MNB.pkl'\n","pickle.dump(MNB, open(filename, 'wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J9hq2H92bzY6","colab_type":"text"},"source":["## Logistic Regression"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-03T22:46:36.311119Z","start_time":"2018-12-03T22:45:55.534590Z"},"id":"7c8HKzsrbzY6","colab_type":"code","colab":{}},"source":["LR = LogisticRegression(class_weight='balanced')\n","lr_tf_model = model(LR, X_tf, target, nsplits=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zpwgg1sqUMIP","colab_type":"code","colab":{}},"source":["import pickle\n","filename = '/content/drive/My Drive/FYP-Embedding/finalized_model_LR.pkl'\n","pickle.dump(LR, open(filename, 'wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AOBQVRv9bzY9","colab_type":"text"},"source":["## Support Vector Machines"]},{"cell_type":"code","metadata":{"id":"uTp1GV_hbzY9","colab_type":"code","colab":{}},"source":["# In order to perform SVM, we first perform PCA and keep the first 20 principal components\n","pca_tfidf = PCA(n_components=20)\n","X_tfidf_pca_50 = pd.DataFrame(pca_tfidf.fit_transform(X_tf))\n","\n","SVM = SVC(class_weight=\"balanced\", probability=True)\n","svm_tf_pca20_model = model(SVM, X_tfidf_pca_50, target, nsplits=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gxZjX5YIbt4I","colab_type":"code","colab":{}},"source":["import pickle\n","filename = '/content/drive/My Drive/FYP-Embedding/finalized_model_SVM.pkl'\n","pickle.dump(SVM, open(filename, 'wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fWJJzjQibzZA","colab_type":"text"},"source":["## Random Forest"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-03T22:47:31.361154Z","start_time":"2018-12-03T22:47:31.357724Z"},"id":"kBTvS_kAbzZA","colab_type":"code","colab":{}},"source":["RF = RandomForestClassifier(\n","    n_estimators=300, max_depth=7, class_weight='balanced')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-03T22:50:14.455207Z","start_time":"2018-12-03T22:47:31.577859Z"},"id":"djNM3ySMbzZD","colab_type":"code","colab":{}},"source":["rf_tf_model = model(RF, X_tf, target, nsplits=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZEQeYFFdb10j","colab_type":"code","colab":{}},"source":["import pickle\n","filename = '/content/drive/My Drive/FYP-Embedding/finalized_model_RF.pkl'\n","pickle.dump(RF, open(filename, 'wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cL-7LWifbzZF","colab_type":"text"},"source":["## Xgboost"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-03T22:50:14.460817Z","start_time":"2018-12-03T22:50:14.457880Z"},"id":"EY5ajdKqbzZF","colab_type":"code","colab":{}},"source":["XGB = XGBClassifier(eval_metric='auc')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-03T23:12:34.280330Z","start_time":"2018-12-03T22:50:14.463220Z"},"id":"XEChMI1rbzZH","colab_type":"code","colab":{}},"source":["xgb_tf_model = model(XGB, X_tf, target, nsplits=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rn2i_Wbxb-eo","colab_type":"code","colab":{}},"source":["import pickle\n","filename = '/content/drive/My Drive/FYP-Embedding/finalized_model_XGB.pkl'\n","pickle.dump(XGB, open(filename, 'wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T78VXryabzZK","colab_type":"text"},"source":["## LightGBM"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-03T23:12:34.286154Z","start_time":"2018-12-03T23:12:34.283156Z"},"id":"bH-hiCZ7bzZK","colab_type":"code","colab":{}},"source":["LGB = lgb.LGBMClassifier(eval_metric='auc', is_unbalance=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-03T23:16:15.834622Z","start_time":"2018-12-03T23:12:34.288972Z"},"id":"fBetw5OrbzZM","colab_type":"code","colab":{}},"source":["lgb_tf_model = model(LGB, X_tf, target, nsplits=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pk5IuFi2cJXN","colab_type":"code","colab":{}},"source":["import pickle\n","filename = '/content/drive/My Drive/FYP-Embedding/finalized_model_LGB.pkl'\n","pickle.dump(LGB, open(filename, 'wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iWmP28C5bzZP","colab_type":"code","colab":{}},"source":["# Parameter Tuning: Random Search\n","# To tune parameters, we are going to do a random search which is more effective in search spaces with a large range in parameters.\n","\n","kf = StratifiedShuffleSplit(n_splits=5, random_state=420)\n","\n","# loop for random search\n","n_iterations = 20\n","\n","print(\"Random search start...\")\n","for col in target.columns:\n","    print(f\"* {types[col]} \")\n","    y = target[col]\n","    roc_auc_mean = []\n","    dict_list = []\n","    for i in range(0, n_iterations):\n","\n","        param_dist = {'n_estimators': choice([250, 300, 350, 400, 450]),\n","                      'bagging_fraction': choice([0.5, 0.7, 0.8, 0.9]),\n","                      'learning_rate': choice([0.05, 0.1, 0.3, 0.5]),\n","                      'is_unbalance': True,\n","                      'max_bin': choice([3, 5, 10, 15, 18, 20, 25]),\n","                      'boosting_type': choice(['gbdt', 'dart']),\n","                      'max_depth': choice([2, 3, 4, 5]),\n","                      'feature_fraction': choice([0.7, 0.8, 0.9]),\n","                      'lambda_l1': choice([0, 10, 20, 30, 40]),\n","                      'objective': 'binary',\n","                      'metric': 'auc'}\n","\n","        roc_l = []\n","\n","        for train, test in kf.split(X_tf, y):\n","\n","            X_train, X_test, y_train, y_test = X_tf.loc[train], X_tf.loc[test], y[train], y[test]\n","\n","            # training\n","            gbm = lgb.LGBMClassifier(**param_dist)\n","            gbm.fit(X_train, y_train)\n","            # predicting\n","            y_pred = np.round(gbm.predict_proba(X_test)[:, 1], 3)\n","            roc = roc_auc_score(y_test, y_pred)\n","            roc_l.append(roc)\n","\n","        roc_array = np.asarray(roc_l)\n","\n","        roc_auc_mean.append(roc_array.mean())\n","        dict_list.append(param_dist)\n","        gc.collect()\n","\n","    results_pd = pd.DataFrame(\n","        {\"roc_auc_mean\": roc_auc_mean, \"parameters\": dict_list})\n","\n","    results_pd.sort_values(\n","        \"roc_auc_mean\", ascending=False, axis=0, inplace=True)\n","    top_pd = results_pd.head(1)\n","    print(f\"--> Best AUC:{top_pd.iloc[0,0]} using {top_pd.iloc[0,1]}\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-03T23:24:20.300703Z","start_time":"2018-12-03T23:24:20.281491Z"},"id":"KkAYAoTAbzZQ","colab_type":"code","colab":{}},"source":["def lgbmodel(X, target, nsplits=4):\n","    '''   Estimates probabilities for observations being in class 1. '''\n","\n","    kf = StratifiedShuffleSplit(n_splits=nsplits, random_state=420)\n","    total_probabilities = defaultdict()\n","    cms = defaultdict()\n","    df = pd.DataFrame(columns=['Average AUC', 'Average F_score'])\n","\n","    types = {'EorI': 'Extroversion vs. Introversion', 'NorS': 'Intuition vs. Sensing',\n","             'TorF': 'Thinking vs. Feeling', 'JorP': 'Judging vs. Perceiving'}\n","\n","    para_list = [{'n_estimators': 400, 'bagging_fraction': 0.8, 'learning_rate': 0.1, 'is_unbalance': True, 'max_bin': 5, 'boosting_type': 'gbdt', 'max_depth': 3, 'feature_fraction': 0.7, 'lambda_l1': 40, 'objective': 'binary', 'metric': 'auc'},\n","                 {'n_estimators': 350, 'bagging_fraction': 0.5, 'learning_rate': 0.05, 'is_unbalance': True, 'max_bin': 15,\n","                     'boosting_type': 'gbdt', 'max_depth': 4, 'feature_fraction': 0.9, 'lambda_l1': 40, 'objective': 'binary', 'metric': 'auc'},\n","                 {'n_estimators': 450, 'bagging_fraction': 0.5, 'learning_rate': 0.1, 'is_unbalance': True, 'max_bin': 18,\n","                     'boosting_type': 'gbdt', 'max_depth': 3, 'feature_fraction': 0.9, 'lambda_l1': 20, 'objective': 'binary', 'metric': 'auc'},\n","                 {'n_estimators': 450, 'bagging_fraction': 0.8, 'learning_rate': 0.05, 'is_unbalance': True, 'max_bin': 5, 'boosting_type': 'gbdt', 'max_depth': 3, 'feature_fraction': 0.9, 'lambda_l1': 10, 'objective': 'binary', 'metric': 'auc'}]\n","\n","    classes = {'EorI': ['Extroverts', 'Introverts'], 'NorS': ['Sensing', 'Intuition'],\n","               'TorF': ['Thinking', 'Feeling'], 'JorP': ['Perceiving', 'Judging']}\n","\n","    t = time.time()\n","    for i, col in enumerate(target.columns):\n","        param = para_list[i]\n","        y = target[col]\n","        all_auc = []\n","        f_score = []\n","        total_probabilities[col] = []\n","        avg_cm = np.zeros(4).reshape(2, 2).astype(int)\n","        for train, test in kf.split(X, y):\n","            X_train, X_test, y_train, y_test = X.loc[train], X.loc[test], y[train], y[test]\n","            gbm = lgb.LGBMClassifier(**param)\n","            gbm.fit(X_train, y_train)\n","            # predicting\n","            probabilities = gbm.predict_proba(X_test)\n","            preds = gbm.predict(X_test)\n","            score = probabilities[:, 1]\n","            total_probabilities[col].append((score, y_test))\n","            all_auc.append(roc_auc_score(y_test, score))\n","            avg_cm += confusion_matrix(y_test, preds, [1, 0])\n","            fscore = threshold_search(y_test, score)\n","            f_score.append(fscore)\n","        avg_cm = avg_cm/nsplits\n","        avg_cm = avg_cm/np.sum(avg_cm)\n","        cms[col] = avg_cm\n","        df.loc[types[col]] = [np.mean(all_auc), np.mean(f_score)]\n","    print(df)\n","    plot_confusion_matrix(cms)\n","    print(f\"Time use:{time.time()-t:.3f}s\")\n","\n","    return get_plot_data(total_probabilities)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-03T23:26:02.333450Z","start_time":"2018-12-03T23:24:20.893769Z"},"id":"K_ubfgy7bzZV","colab_type":"code","colab":{}},"source":["lgb_tf_model_t = lgbmodel(X_tf, target, nsplits=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"58UQymMBuS7c","colab_type":"code","colab":{}},"source":["import pickle\n","filename = '/content/drive/My Drive/FYP-Embedding/finalized_model_LGB_1.sav'\n","pickle.dump(X_tf, open(filename, 'wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XNN-o0_abzZX","colab_type":"code","colab":{}},"source":["# Feature Importance\n","para_list = [{'n_estimators': 400, 'bagging_fraction': 0.8, 'learning_rate': 0.1, 'is_unbalance': True, 'max_bin': 5, 'boosting_type': 'gbdt', 'max_depth': 3, 'feature_fraction': 0.7, 'lambda_l1': 40, 'objective': 'binary', 'metric': 'auc'},\n","             {'n_estimators': 350, 'bagging_fraction': 0.5, 'learning_rate': 0.05, 'is_unbalance': True, 'max_bin': 15,\n","                 'boosting_type': 'gbdt', 'max_depth': 4, 'feature_fraction': 0.9, 'lambda_l1': 40, 'objective': 'binary', 'metric': 'auc'},\n","             {'n_estimators': 450, 'bagging_fraction': 0.5, 'learning_rate': 0.1, 'is_unbalance': True, 'max_bin': 18,\n","                 'boosting_type': 'gbdt', 'max_depth': 3, 'feature_fraction': 0.9, 'lambda_l1': 20, 'objective': 'binary', 'metric': 'auc'},\n","             {'n_estimators': 450, 'bagging_fraction': 0.8, 'learning_rate': 0.05, 'is_unbalance': True, 'max_bin': 5, 'boosting_type': 'gbdt', 'max_depth': 3, 'feature_fraction': 0.9, 'lambda_l1': 10, 'objective': 'binary', 'metric': 'auc'}]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nKyYrUhqbzZZ","colab_type":"code","colab":{}},"source":["X_tf.drop(['ni', 'ne', 'sx', 'fe'], axis=1, inplace=True)\n","for i in range(4):\n","    label = target.columns\n","    y = target.values[:, 0]\n","    # fit model on training data\n","    LGB = lgb.LGBMClassifier(**para_list[i])\n","    LGB.fit(X_tf, y)\n","    # plot feature importance\n","    ax = lgb.plot_importance(LGB, max_num_features=15)\n","\n","    fig = ax.figure\n","    fig.set_size_inches(10, 5)\n","    plt.title(f\"Feature_Importance_for_{label[i]}\")\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yqQdOhGnbzZb","colab_type":"text"},"source":["# Ensemble Learning: Voting Classifier"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-03T23:28:35.160899Z","start_time":"2018-12-03T23:28:35.157175Z"},"id":"8mN5kMq6bzZc","colab_type":"code","colab":{}},"source":["pm = {'n_estimators': 450, 'bagging_fraction': 0.5,\n","      'learning_rate': 0.05, 'is_unbalance': True,\n","      'max_bin': 18, 'boosting_type': 'gbdt',\n","      'max_depth': 3, 'feature_fraction': 0.9,\n","      'lambda_l1': 20, 'objective': 'binary', 'metric': 'auc'}\n","Lgbm = lgb.LGBMClassifier(**pm)\n","\n","voting_clf = VotingClassifier(estimators=[('lgbm', Lgbm),\n","                                          ('xgb', XGB),\n","                                          ('lr', LR),\n","                                          ('rf', RF)],\n","                              voting='soft')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-03T23:58:21.756107Z","start_time":"2018-12-03T23:28:36.344858Z"},"id":"oOKgYT7LbzZe","colab_type":"code","colab":{}},"source":["voting = model(voting_clf, X_tf, target, nsplits=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h0VvYFSDysJn","colab_type":"code","colab":{}},"source":["import pickle\n","filename = '/content/drive/My Drive/FYP-Embedding/finalized_model_1.pkl'\n","pickle.dump(voting_clf, open(filename, 'wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QNH1gY1vbzZf","colab_type":"text"},"source":["# Performance Evaluation \n","## ROC-AUC plot"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-04T00:09:55.906120Z","start_time":"2018-12-04T00:09:55.893160Z"},"id":"K8zCUbu8bzZg","colab_type":"code","colab":{}},"source":["def auc_plot(model_list, model_names, plot_type):\n","    '''\n","    From model list and model names, plots ROC curves \n","    '''\n","    fig, axs = plt.subplots(2, 2, figsize=(\n","        15, 15), facecolor='w', edgecolor='b')\n","    axs = axs.flatten()\n","    abbrev = {'EorI': 'Extroversion vs. Introversion', 'NorS': 'Intuition vs. Sensing',\n","              'TorF': 'Thinking vs. Feeling', 'JorP': 'Judging vs. Perceiving'}\n","    colors = ['b', 'g', 'c', 'm', 'y']\n","\n","    if plot_type == 'roc':\n","        y_axis = 'est_tpr'\n","        auc_type = 'auc_roc'\n","        plot_name = 'ROC'\n","        legend_position = 'lower right'\n","        y_label = 'True Positive Rate'\n","        x_label = 'False Positive Rate'\n","        legend_title = 'Avg ROC-AUC Score'\n","    elif plot_type == 'pr':\n","        y_axis = 'est_pr'\n","        auc_type = 'auc_pr'\n","        plot_name = 'Precision vs Recall'\n","        legend_position = 'lower left'\n","        y_label = 'Precision'\n","        x_label = 'Recall'\n","        legend_title = 'Avg PR-AUC Score'\n","    else:\n","        raise AttributeError('Invalid plot type')\n","\n","    for x in range(len(model_list)):\n","        plot_data = model_list[x]\n","        types = list(plot_data.keys())\n","\n","        for i in range(len(types)):\n","            x_axis = plot_data[types[i]]['base_x']\n","            est_y = plot_data[types[i]][y_axis]\n","            auc = plot_data[types[i]][auc_type]\n","            axs[i].plot(x_axis, est_y, colors[x], linewidth=1,\n","                        label='%s = %0.2f' % (model_names[x], auc))\n","            if plot_type == 'roc':\n","                axs[i].plot([0, 1], [0, 1], 'r--', linewidth=1)\n","            axs[i].legend(loc=legend_position,\n","                          title=legend_title, frameon=False)\n","            axs[i].set_xlim([0, 1])\n","            axs[i].set_ylim([0, 1])\n","            axs[i].set_ylabel(y_label)\n","            axs[i].set_xlabel(x_label)\n","            axs[i].set_title(f'{plot_name} for {abbrev[types[i]]}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-04T00:09:56.091111Z","start_time":"2018-12-04T00:09:56.087932Z"},"id":"kh5rr5yEbzZj","colab_type":"code","colab":{}},"source":["model_list = [lr_tf_model, lgb_tf_model_t, xgb_tf_model, rf_tf_model, voting]\n","model_names = ['Logistic', 'LGB tuned', 'XGB', 'RF', 'VOTING']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-04T00:09:57.114274Z","start_time":"2018-12-04T00:09:56.236806Z"},"id":"dUYGZLWabzZl","colab_type":"code","colab":{}},"source":["auc_plot(model_list, model_names, plot_type='roc')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U4eCjEn2bzZn","colab_type":"text"},"source":["## Precision Recall - AUC"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-12-04T00:09:58.542677Z","start_time":"2018-12-04T00:09:57.560595Z"},"id":"dKrl0eIQbzZn","colab_type":"code","colab":{}},"source":["auc_plot(model_list, model_names, plot_type='pr')"],"execution_count":0,"outputs":[]}]}